{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0376b39a",
   "metadata": {},
   "source": [
    "# d=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33711a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from qecdec import RotatedSurfaceCode_Memory\n",
    "from learned_decoders import *\n",
    "from train_utils import *\n",
    "from datetime import datetime\n",
    "\n",
    "# Set experiment parameters.\n",
    "d = 5  # code distance\n",
    "rounds = 5  # number of rounds of stabilizer measurements\n",
    "p = 0.01  # physical error rate\n",
    "\n",
    "# Set training parameters.\n",
    "num_epochs = 20\n",
    "batch_size = 256\n",
    "model_kwargs = dict(num_iters=5)\n",
    "optimizer_kwargs = dict(lr=0.002)\n",
    "loss_fn_kwargs = dict(beta=1.0, skip_iters=0)\n",
    "lr_scheduler_kwargs=dict(factor=0.2, patience=3, threshold=1e-3, threshold_mode=\"abs\")\n",
    "early_stopper_kwargs = dict(patience=5, min_delta=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9094f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of error mechanisms: 186\n",
      "Number of detectors: 72\n",
      "Number of observables: 1\n"
     ]
    }
   ],
   "source": [
    "expmt = RotatedSurfaceCode_Memory(\n",
    "    d=d,\n",
    "    rounds=rounds,\n",
    "    basis='Z',\n",
    "    data_qubit_error_rate=p,\n",
    "    meas_error_rate=p,\n",
    ")\n",
    "print(\"Number of error mechanisms:\", expmt.num_error_mechanisms)\n",
    "print(\"Number of detectors:\", expmt.num_detectors)\n",
    "print(\"Number of observables:\", expmt.num_observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29c27ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling shots from the noisy circuit...\n",
      "Added 8165 samples to the training dataset.\n",
      "Added 815 samples to the validation dataset.\n",
      "Generating all weight-1 errors...\n",
      "Added 186 samples to the training dataset.\n",
      "Generating all weight-2 errors...\n",
      "Added 17205 samples to the training dataset.\n",
      "Size of train_dataset: 25556\n",
      "Size of val_dataset: 815\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = build_datasets(\n",
    "    expmt,\n",
    "    train_shots=10_000,\n",
    "    val_shots=1_000,\n",
    "    seed=42,\n",
    "    train_all_wt1_errors=True,\n",
    "    train_all_wt2_errors=True,\n",
    "    remove_trivial_syndromes=True,\n",
    ")\n",
    "\n",
    "model = LearnedDMemBP(expmt.chkmat, expmt.prior, **model_kwargs)\n",
    "loss_fn = DecodingLoss(expmt.chkmat, expmt.obsmat, **loss_fn_kwargs)\n",
    "metric = DecodingMetric(expmt.chkmat, expmt.obsmat)\n",
    "optimizer = torch.optim.Adam(model.parameters(), **optimizer_kwargs)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, **lr_scheduler_kwargs)\n",
    "early_stopper=EarlyStopper(**early_stopper_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadb66b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 100/100 [00:16<00:00,  6.04it/s, avg_loss=0.767078, grad_norm=0.303137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary:\n",
      "  Avg Train Loss: 0.767078\n",
      "  Avg Val Loss: 0.832159\n",
      "  wrong_syndrome_rate: 0.050307\n",
      "  wrong_observable_rate: 0.007362\n",
      "  failure_rate: 0.050307\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 100/100 [00:16<00:00,  6.11it/s, avg_loss=0.704019, grad_norm=0.272567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary:\n",
      "  Avg Train Loss: 0.704019\n",
      "  Avg Val Loss: 0.784984\n",
      "  wrong_syndrome_rate: 0.050307\n",
      "  wrong_observable_rate: 0.011043\n",
      "  failure_rate: 0.050307\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 100/100 [00:16<00:00,  6.06it/s, avg_loss=0.677190, grad_norm=0.196400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Summary:\n",
      "  Avg Train Loss: 0.677190\n",
      "  Avg Val Loss: 0.765155\n",
      "  wrong_syndrome_rate: 0.045399\n",
      "  wrong_observable_rate: 0.012270\n",
      "  failure_rate: 0.045399\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 100/100 [00:16<00:00,  6.04it/s, avg_loss=0.662672, grad_norm=0.128141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary:\n",
      "  Avg Train Loss: 0.662672\n",
      "  Avg Val Loss: 0.756020\n",
      "  wrong_syndrome_rate: 0.041718\n",
      "  wrong_observable_rate: 0.013497\n",
      "  failure_rate: 0.042945\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 100/100 [00:16<00:00,  6.17it/s, avg_loss=0.653461, grad_norm=0.132810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Summary:\n",
      "  Avg Train Loss: 0.653461\n",
      "  Avg Val Loss: 0.752269\n",
      "  wrong_syndrome_rate: 0.039264\n",
      "  wrong_observable_rate: 0.013497\n",
      "  failure_rate: 0.040491\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 100/100 [00:16<00:00,  6.17it/s, avg_loss=0.647153, grad_norm=0.157165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Summary:\n",
      "  Avg Train Loss: 0.647153\n",
      "  Avg Val Loss: 0.750873\n",
      "  wrong_syndrome_rate: 0.035583\n",
      "  wrong_observable_rate: 0.013497\n",
      "  failure_rate: 0.036810\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 100/100 [00:16<00:00,  6.07it/s, avg_loss=0.642682, grad_norm=0.124679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Summary:\n",
      "  Avg Train Loss: 0.642682\n",
      "  Avg Val Loss: 0.751024\n",
      "  wrong_syndrome_rate: 0.036810\n",
      "  wrong_observable_rate: 0.013497\n",
      "  failure_rate: 0.038037\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 100/100 [00:16<00:00,  6.16it/s, avg_loss=0.639662, grad_norm=0.150676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Summary:\n",
      "  Avg Train Loss: 0.639662\n",
      "  Avg Val Loss: 0.750999\n",
      "  wrong_syndrome_rate: 0.038037\n",
      "  wrong_observable_rate: 0.013497\n",
      "  failure_rate: 0.039264\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 100/100 [00:16<00:00,  6.04it/s, avg_loss=0.637262, grad_norm=0.145191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Summary:\n",
      "  Avg Train Loss: 0.637262\n",
      "  Avg Val Loss: 0.751149\n",
      "  wrong_syndrome_rate: 0.036810\n",
      "  wrong_observable_rate: 0.014724\n",
      "  failure_rate: 0.038037\n",
      "  Learning Rate: 0.002000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 100/100 [00:16<00:00,  6.11it/s, avg_loss=0.635644, grad_norm=0.136541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Summary:\n",
      "  Avg Train Loss: 0.635644\n",
      "  Avg Val Loss: 0.750919\n",
      "  wrong_syndrome_rate: 0.035583\n",
      "  wrong_observable_rate: 0.012270\n",
      "  failure_rate: 0.036810\n",
      "  Learning Rate: 0.000400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 100/100 [00:16<00:00,  6.04it/s, avg_loss=0.633803, grad_norm=0.062244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Summary:\n",
      "  Avg Train Loss: 0.633803\n",
      "  Avg Val Loss: 0.750666\n",
      "  wrong_syndrome_rate: 0.034356\n",
      "  wrong_observable_rate: 0.012270\n",
      "  failure_rate: 0.035583\n",
      "  Learning Rate: 0.000400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 100/100 [00:16<00:00,  5.91it/s, avg_loss=0.633886, grad_norm=0.158321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Summary:\n",
      "  Avg Train Loss: 0.633886\n",
      "  Avg Val Loss: 0.750557\n",
      "  wrong_syndrome_rate: 0.034356\n",
      "  wrong_observable_rate: 0.012270\n",
      "  failure_rate: 0.035583\n",
      "  Learning Rate: 0.000400\n",
      "\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "train_decoder(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    loss_fn,\n",
    "    metric,\n",
    "    optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    device=\"cpu\",\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    early_stopper=early_stopper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a38b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.stack([x.detach() for x in model.gamma]).cpu().numpy().astype(np.float64)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "np.save(f\"learned_params/dmembp_d{d}_{timestamp}_gamma.npy\", gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda5aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
